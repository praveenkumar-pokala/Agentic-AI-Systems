{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97126ff9",
   "metadata": {},
   "source": [
    "# Memory-Augmented Agent Demo\n",
    "\n",
    "Goal: show how an AI assistant can remember stable preferences across turns, without leaking everything or storing risky data.\n",
    "\n",
    "This notebook demonstrates four stages:\n",
    "\n",
    "1. **Scratchpad build** – summarize the latest user message so the assistant stays on-track in this session.\n",
    "2. **Answer with memory** – combine:\n",
    "   - long-term memory (persistent profile in `memory.json`)\n",
    "   - scratchpad (what we're doing right now)\n",
    "   - user's question\n",
    "   and generate a VP-style answer.\n",
    "3. **Memory write decision** – ask a model if anything NEW from this conversation should enter long-term memory.\n",
    "4. **Persist** – only if the model explicitly says `SAVE: {\"key\": ..., \"value\": ...}`.\n",
    "\n",
    "This is how you build continuity and personalization you can defend in front of leadership."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a088a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, textwrap\n",
    "from pathlib import Path\n",
    "from openai import OpenAI\n",
    "\n",
    "# Before running:\n",
    "# os.environ['OPENAI_API_KEY'] = 'sk-...'\n",
    "\n",
    "client = OpenAI(api_key=os.environ.get('OPENAI_API_KEY'))\n",
    "MEMORY_FILE = Path('memory.json')\n",
    "\n",
    "def load_memory():\n",
    "    if MEMORY_FILE.exists():\n",
    "        return json.load(open(MEMORY_FILE, 'r', encoding='utf-8'))\n",
    "    return {'user_profile': {}, 'last_updated': None}\n",
    "\n",
    "def save_memory(mem):\n",
    "    mem['last_updated'] = 'updated_from_notebook'\n",
    "    json.dump(mem, open(MEMORY_FILE, 'w', encoding='utf-8'), indent=2)\n",
    "\n",
    "SYSTEM_SCRATCHPAD = \"\"\"\n",
    "You are an analyst.\n",
    "Summarize the user's latest message into a compact scratchpad context that captures:\n",
    "- What the user is trying to do right now\n",
    "- Any constraints or style requests\n",
    "Do NOT add new facts. Be concise.\n",
    "Return ONLY the summary text.\n",
    "\"\"\"\n",
    "\n",
    "def build_scratchpad(user_msg: str) -> str:\n",
    "    resp = client.responses.create(\n",
    "        model='o4-mini',\n",
    "        input=[\n",
    "            {'role': 'system', 'content': SYSTEM_SCRATCHPAD},\n",
    "            {'role': 'user', 'content': user_msg},\n",
    "        ],\n",
    "    )\n",
    "    if hasattr(resp, 'output_text'):\n",
    "        return resp.output_text.strip()\n",
    "    try:\n",
    "        return resp.choices[0].message.content.strip()\n",
    "    except Exception:\n",
    "        if hasattr(resp, 'output'):\n",
    "            if isinstance(resp.output, list):\n",
    "                return '\\n'.join(str(x) for x in resp.output).strip()\n",
    "            return str(resp.output)\n",
    "        return str(resp).strip()\n",
    "\n",
    "SYSTEM_ANSWER = \"\"\"\n",
    "You are an executive briefing assistant.\n",
    "\n",
    "You will receive:\n",
    "1. LONG_TERM_MEMORY: stable known preferences about this user\n",
    "2. SCRATCHPAD: summary of what they just asked\n",
    "3. USER_QUESTION: the raw question\n",
    "\n",
    "Your job:\n",
    "- Answer USER_QUESTION directly\n",
    "- Respect tone/style preferences in LONG_TERM_MEMORY\n",
    "- Highlight risk, operational impact, cost if relevant\n",
    "- Be concise and VP-ready\n",
    "\n",
    "Output only the final answer for the user.\n",
    "\"\"\"\n",
    "\n",
    "def answer_with_memory(long_term_memory: dict, scratchpad: str, user_question: str) -> str:\n",
    "    composite_prompt = textwrap.dedent(f\"\"\"\n",
    "    LONG_TERM_MEMORY:\n",
    "    {json.dumps(long_term_memory, indent=2)}\n",
    "\n",
    "    SCRATCHPAD:\n",
    "    {scratchpad}\n",
    "\n",
    "    USER_QUESTION:\n",
    "    {user_question}\n",
    "    \"\"\").strip()\n",
    "\n",
    "    resp = client.responses.create(\n",
    "        model='o4-mini',\n",
    "        input=[\n",
    "            {'role': 'system', 'content': SYSTEM_ANSWER},\n",
    "            {'role': 'user', 'content': composite_prompt},\n",
    "        ],\n",
    "    )\n",
    "    if hasattr(resp, 'output_text'):\n",
    "        return resp.output_text.strip()\n",
    "    try:\n",
    "        return resp.choices[0].message.content.strip()\n",
    "    except Exception:\n",
    "        if hasattr(resp, 'output'):\n",
    "            if isinstance(resp.output, list):\n",
    "                return '\\n'.join(str(x) for x in resp.output).strip()\n",
    "            return str(resp.output)\n",
    "        return str(resp).strip()\n",
    "\n",
    "SYSTEM_MEMORY_WRITE = \"\"\"\n",
    "You are a memory write policy checker for an AI assistant.\n",
    "\n",
    "You get:\n",
    "- The user's latest message\n",
    "- The assistant's final answer\n",
    "- The existing LONG_TERM_MEMORY (JSON)\n",
    "\n",
    "Your job:\n",
    "1. Decide if there's a NEW stable preference or identity detail that would be valuable long-term.\n",
    "2. If yes, respond EXACTLY:\n",
    "SAVE: {\"key\": \"...\", \"value\": \"...\"}\n",
    "3. If not, respond EXACTLY:\n",
    "NOSAVE\n",
    "\n",
    "Rules:\n",
    "- Do NOT store secrets, credentials, medical details, or anything too sensitive.\n",
    "- Store only durable preferences or role context that will clearly help future answers.\n",
    "\"\"\"\n",
    "\n",
    "def propose_memory_update(long_term_memory: dict, user_msg: str, final_answer: str) -> str:\n",
    "    composite_prompt = textwrap.dedent(f\"\"\"\n",
    "    USER_MESSAGE:\n",
    "    {user_msg}\n",
    "\n",
    "    ASSISTANT_FINAL_ANSWER:\n",
    "    {final_answer}\n",
    "\n",
    "    CURRENT_LONG_TERM_MEMORY:\n",
    "    {json.dumps(long_term_memory, indent=2)}\n",
    "\n",
    "    Produce memory decision now.\n",
    "    \"\"\").strip()\n",
    "\n",
    "    resp = client.responses.create(\n",
    "        model='o4-mini',\n",
    "        input=[\n",
    "            {'role': 'system', 'content': SYSTEM_MEMORY_WRITE},\n",
    "            {'role': 'user', 'content': composite_prompt},\n",
    "        ],\n",
    "    )\n",
    "    if hasattr(resp, 'output_text'):\n",
    "        return resp.output_text.strip()\n",
    "    try:\n",
    "        return resp.choices[0].message.content.strip()\n",
    "    except Exception:\n",
    "        if hasattr(resp, 'output'):\n",
    "            if isinstance(resp.output, list):\n",
    "                return '\\n'.join(str(x) for x in resp.output).strip()\n",
    "            return str(resp.output)\n",
    "        return str(resp).strip()\n",
    "\n",
    "def apply_memory_update(mem: dict, decision: str) -> (dict, str):\n",
    "    decision = decision.strip()\n",
    "    if decision.startswith('NOSAVE'):\n",
    "        return mem, 'No persistent memory update.'\n",
    "\n",
    "    if decision.startswith('SAVE:'):\n",
    "        payload = decision[len('SAVE:'):].strip()\n",
    "        try:\n",
    "            data = json.loads(payload)\n",
    "            key = data.get('key')\n",
    "            value = data.get('value')\n",
    "        except Exception:\n",
    "            return mem, f'Memory decision malformed: {decision}'\n",
    "\n",
    "        if not key or not value:\n",
    "            return mem, f'Memory decision missing key/value: {decision}'\n",
    "\n",
    "        if 'user_profile' not in mem or not isinstance(mem['user_profile'], dict):\n",
    "            mem['user_profile'] = {}\n",
    "        mem['user_profile'][key] = value\n",
    "        save_memory(mem)\n",
    "        return mem, f'Stored memory: {key} = {value}'\n",
    "\n",
    "    return mem, f'Unrecognized memory decision: {decision}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e94857d",
   "metadata": {},
   "source": [
    "### Demo conversation turn\n",
    "Pretend the user says:\n",
    "\n",
    "> \"I'm visiting Hyderabad again next week to meet execs. Give me a short briefing with risks and travel tips. I prefer VP tone and no fluff.\"\n",
    "\n",
    "We'll walk through:\n",
    "1. load existing memory.json\n",
    "2. build scratchpad\n",
    "3. answer_with_memory\n",
    "4. propose_memory_update\n",
    "5. apply_memory_update\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c8916f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_msg = (\n",
    "    \"I'm visiting Hyderabad again next week to meet execs. \"\n",
    "    \"Give me a short briefing with risks and travel tips. \"\n",
    "    \"I prefer VP tone and no fluff.\"\n",
    ")\n",
    "\n",
    "mem = load_memory()\n",
    "scratch = build_scratchpad(user_msg)\n",
    "final_answer = answer_with_memory(mem, scratch, user_msg)\n",
    "decision = propose_memory_update(mem, user_msg, final_answer)\n",
    "updated_mem, note = apply_memory_update(mem, decision)\n",
    "\n",
    "print('===== SCRATCHPAD =====')\n",
    "print(scratch)\n",
    "print('\\n===== FINAL ANSWER =====')\n",
    "print(final_answer)\n",
    "print('\\n===== MEMORY DECISION =====')\n",
    "print(decision)\n",
    "print('\\n===== MEMORY UPDATE NOTE =====')\n",
    "print(note)\n",
    "print('\\n===== UPDATED MEMORY =====')\n",
    "print(json.dumps(updated_mem, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a612c38",
   "metadata": {},
   "source": [
    "### Why this matters\n",
    "This pipeline:\n",
    "\n",
    "- Uses **long-term memory** (persistent JSON) to maintain user profile.\n",
    "- Builds a **short-term scratchpad** so the model stays on track in the current turn without full chat history.\n",
    "- Uses a **memory write policy step** to decide if anything new should be remembered and logs that decision.\n",
    "\n",
    "That last part is critical for safety and compliance:\n",
    "you can review every proposed memory before it gets saved, or even require a human approval step in regulated environments.\n",
    "\n",
    "This is how you move from a stateless chatbot to a durable AI chief of staff with audit trails."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
